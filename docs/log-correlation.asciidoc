ifdef::env-github[]
NOTE: For the best reading experience,
please view this documentation at https://www.elastic.co/guide/en/apm/agent/java[elastic.co]
endif::[]

[[log-correlation]]
== Log correlation

Log correlation allows you to navigate to all logs belonging to a particular trace and vice-versa:
for a specific log, see in which context it has been logged and which parameters the user provided.

NOTE: Starting in APM agent version 1.30.0, log correlation is enabled by default.
In previous versions, log correlation must be explicitly enabled by setting
the `enable_log_correlation` configuration variable to `true`.

[float]
[[log-correlation-ingest]]
=== Step 1: Ingest your application logs into Elasticsearch

To get started with log correlation, your logs have to be ingested into Elasticsearch first.

The easiest way to get started with that is by automatically reformatting your application logs into ECS-compatible
format through the Java agent's logging frameworks auto-instrumentation. Check out the <<config-log-ecs-reformatting>>
configuration for more details.

NOTE: the <<config-log-ecs-reformatting, `log_ecs_reformatting`>> configuration is still experimental and may change
in the future. However, since it is effortless, it may be your first choice to try out.

Another way to make logs ECS-compatible is {ecs-logging-java-ref}/intro.html[Java ECS logging], which
provides layouts/encoders for Logback, log4j2, and log4j.
These layouts/encoders convert a log event into an ECS-compatible JSON structure. Using minimal Filebeat configuration,
you can ingest these logs into Elasticsearch.
Head over to the documentation to learn more: {ecs-logging-java-ref}/intro.html[Java ECS logging documentation].

If youâ€™re using plain-text logs it's recommended to parse out specific parts of the logs,
like the timestamp, the log level, and the message. One way to do this is by using an {ref}/ingest.html[ingest pipeline] with a {ref}/grok-processor.html[grok processor].

[float]
[[log-correlation-extract-ids]]
=== Step 2: Extract the ID fields

In order to correlate logs from your application with transactions captured by the Elastic APM Java Agent,
the agent injects the following IDs into https://www.slf4j.org/api/org/slf4j/MDC.html[slf4j-MDC]-equivalents of
<<supported-logging-frameworks, supported logging frameworks>>:

* {ecs-ref}/ecs-tracing.html[`transaction.id`]
* {ecs-ref}/ecs-tracing.html[`trace.id`]
* {ecs-ref}/ecs-error.html[`error.id`]

If you are using https://github.com/elastic/java-ecs-logging[Java ECS logging], there's nothing to do in this step.
The IDs in the MDC are automatically added to the right fields.

For plain text logs, use the pattern layout of your logging implementation to write the MDC values to your log file.
If you are using Logback or log4j, add `%X` to the format to log all MDC values or `%X{trace.id}` to only log the trace id.
With the help of Filebeat and Logstash or an Elasticsearch ingest pipeline,
you can parse out the IDs from the logs and put them in the {ecs-ref}/ecs-tracing.html[`transaction.id`], {ecs-ref}/ecs-tracing.html[`trace.id`]
and {ecs-ref}/ecs-error.html[`error.id`] fields.
